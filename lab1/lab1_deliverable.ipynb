{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MALIS Lab Session 1 - Fall 2019\n",
    "October 15 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this lab is to practice with linear models for both regression and classification via simple experiments. \n",
    "\n",
    "#### Learning goals\n",
    "After this lab, you should be able to:\n",
    "1. Interpret the coefficent estimates produced by a linear model\n",
    "2. Be familiar with the use of polynomial and categorical features\n",
    "3. Be familiar with the building blocks of a pipeline to make building, fitting, and tracking models easier\n",
    "3. Be able to make an informed choice of model based on the data at hand\n",
    "4. Understand the key differences between nearest neighbor and linear models\n",
    "\n",
    "#### Instructions:\n",
    "Experiments should be made by groups of two students. Each group should produce a Jupyter Notebook with all their results and comments. We strongly encourage the addition of plots and visual representations to the report, bearing in mind that comments on graphical data are still necessary. Code for adding images to your notebook: ```<img src=\"path/to/image.png\" />```.\n",
    "\n",
    "Submit your complete notebook as an archive (tar -cf groupXnotebook.tar lab2/). **Deadline for submitting your notebook:** 28 October 2018 23:59:59 (CET) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Linear Regression\n",
    "In this part, we will be working with a dataset scraped by <a href=\"https://www.kaggle.com/mauryashubham/linear-regression-to-predict-market-value/data\">Shubham Maurya</a>, which collects facts about players in the English Premier League as of 2017. His original goal was to establish if there was a relationship between a player's popularity and his market value, as estimated by transfermrkt.com.\n",
    "\n",
    "**Your goal is to fit a model able to predict a player's market value.**\n",
    "\n",
    "The dataset contains the following information:\n",
    "\n",
    "| **Field**   |     **Description**      |  \n",
    "|-------------|-------------|\n",
    "| name   |  Name of the player | \n",
    "| club   |  Club of the player |\n",
    "| age    | Age of the player |\n",
    "|position| The usual position on the pitch|\n",
    "|position_cat| 1 for attackers, 2 for midfielders, 3 for defenders, 4 for goalkeepers|\n",
    "|market_value| As on transfermrkt.com on July 20th, 2017|\n",
    "|page_views| Average daily Wikipedia page views from September 1, 2016 to May 1, 2017|\n",
    "|fpl_value| Value in Fantasy Premier League as on July 20th, 2017|\n",
    "|fpl_sel| % of FPL players who have selected that player in their team|\n",
    "|fpl_points| FPL points accumulated over the previous season|\n",
    "|region| 1 for England, 2 for EU, 3 for Americas, 4 for Rest of World|\n",
    "|nationality| Player's nationality|\n",
    "|new_foreign| Whether a new signing from a different league, for 2017/18 (till 20th July)|\n",
    "|age_cat| a categorical version of the Age feature|\n",
    "|club_id| a numerical version of the Club feature|\n",
    "|big_club| Whether one of the Top 6 clubs|\n",
    "|new_signing| Whether a new signing for 2017/18 (till 20th July)|\n",
    "\n",
    "**Step 1:** The very first step is to have a deeper look into the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_df = pd.read_csv(\"data/football_data.csv\")\n",
    "\n",
    "print(league_df.dtypes)     # Prints out the data types associated to each of the fields in the table\n",
    "league_df.head()            # df.head(N) displays the top N entries of a dataframe. If no arguments shows 5 by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_df.describe() #Generates descriptive statistics that summarize the central tendency, dispersion and shape of a datasetâ€™s distribution (numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 - Prepare the data:** As we did with the Men's Olympic 100m data, we will split our data into two sets: One data set for training and another one that we will use at the end to test our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in two. For the purpose of this lab, you do not need to worry about how data is split. This is done for you.\n",
    "train = pd.read_csv('data/train_football_data.csv')\n",
    "test = pd.read_csv('data/test_football_data.csv')\n",
    "\n",
    "# #We create array variables to store our target variable, which is the market value of a player\n",
    "y_train = train['market_value']\n",
    "y_test = test['market_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a lot of features that can be used to build the model. We will start by using <code>age, fpl_value, big_club</code> and <code>page_views</code>. \n",
    "\n",
    "\\begin{equation}\n",
    " \\hat{y} = W_0 + W_1x_{age} + W_2x_{fplavalue} + W_3x_{bigclub} + W_4x_{pageviews}\n",
    "\\end{equation}\n",
    "\n",
    "The function below prepares the data by selecting these features and then adding the dummy variable $x_0 = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X(ds):\n",
    "    '''\n",
    "    Prepares training data by selecting the features to use and the adding the dummy variable x[0] = 1\n",
    "    '''\n",
    "    X_cols = ds[['age', 'fpl_value', 'big_club']].copy()\n",
    "    X_cols['sqrt_page_views'] = np.sqrt(ds[['page_views']])\n",
    "    X = X_cols.values\n",
    "    X = X.reshape(len(X_cols),-1)\n",
    "    \n",
    "    #We add the dummy x_0\n",
    "    poly = PolynomialFeatures(1)  \n",
    "    X = poly.fit_transform(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call prepare_X to prepare training data. We do the same for test data, although this will only be used later on.\n",
    "X = prepare_X(train)\n",
    "X_test = prepare_X(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3 - Training:** The line of code below calls the function fit_model which has been already implemented for you (see utils.py but, do not edit it). By running it you obtain the estimated parameters $\\hat{\\mathbf{W}}$ of the linear regressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = utils.fit_model(X,y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4 - Predict and evaluate:** The function <code>run</code> below collects all the necessary steps to predict and then evaluate a particular model. As inputs it receives the model parameters (i.e. $\\mathbf{W}$), an input dataset <code>X_test</code> and the corresponding targets <code>y_test</code>. Internally, it calls two functions:\n",
    "\n",
    "1. <code>predict</code> which estimates $\\hat{y}=\\mathbf{X\\hat{W}}$ given the model parameters and an input sample and then returns the predicted targets.\n",
    "2. <code>MSE</code> which computes the mean squared error (and then returns it):\n",
    "\\begin{equation}\n",
    "MSE = \\dfrac{1}{N}\\sum_{i=1}^{N}(y_i -\\hat{y}_i)^2\n",
    "\\end{equation}\n",
    "where $i$ denotes the index of the $i^{th}$ sample and $N$ the total number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 1:** Implement <code>predict(W,X)</code> and <code>MSE(y, y_hat)</code>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(W, X_test, y_test):\n",
    "    '''\n",
    "    Collects the necessary steps to predict and then evaluate a particular model. \n",
    "    As inputs it receives the model parameters an input dataset X_test and the corresponding targets y_test\n",
    "    It returs the MSE.\n",
    "    '''\n",
    "    y_hat_test = predict(W,X_test)\n",
    "    mse = MSE(y_test, y_hat_test)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "def predict(W, X):\n",
    "    #Your code here\n",
    "\n",
    "def MSE(y, y_hat):\n",
    "    #Your code here\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can have a look at the parameters of your model and also at how well it fits the training data according to the MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = run(W,X,y_train)\n",
    "\n",
    "print('*******************************************************************************************')\n",
    "print('[W_0,W] : [', W[0],',', W[1:], ']' )\n",
    "print('MSE: ', mse)\n",
    "print('*******************************************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated weights W (excluding $W_0$) are associated to 'age', 'fpl_value', 'big_club' and 'log_page_views'. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Question 1:** How do you interpret the valued of each of these parameters? Based on this information, what can you say about the effect in a player's market value of his:\n",
    "    1. age?\n",
    "    2. number of page views?\n",
    "    3. fpl value\n",
    "\n",
    "Which of this feature seems to have the largest effect on a player's value?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Including polynomial features\n",
    "A *scatter matrix* a pair-wise scatter plot of several variables presented in a matrix format. It can be used to determine whether the variables are correlated and whether the correlation is positive or negative.\n",
    "\n",
    "From the scatter matrix below we can explore the relationship that each \"potential\" input variable has with the target variable, the market value. \n",
    "\n",
    "When looking at the correlation between age and market value (first column, third row), it does not seem to be linear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(train, figsize=(30,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [9.5, 6]\n",
    "plt.scatter(X[:,1], y_train.values)\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('market value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore considering a more complex effect of the age by including a quadratic term: \n",
    "\n",
    "\\begin{equation}\n",
    " \\hat{y} = w_0 + w_1*x_{age} + w_2x_{fplavalue} + w_3*x_{bigclub} + w_4*x_{pageviews} + w_5*x_{age}^2\n",
    "\\end{equation}\n",
    "\n",
    "The function below prepares the datato fit to this new model.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 2:** Complete the code below to include the quadratic term regarding the age.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X_with_age(ds):\n",
    "    #Your code here\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sqr = prepare_X_with_age(train)\n",
    "X_sqr_test = prepare_X_with_age(test)\n",
    "\n",
    "W_sqr = utils.fit_model(X_sqr, y_train)\n",
    "mse_sqr = run(W_sqr,X_sqr, y_train)\n",
    "\n",
    "print('***************************** Results with age^2 *******************************************')\n",
    "print('[W_0,W] : [', W_sqr[0],',', W_sqr[1:], ']' )\n",
    "print('MSE: ', mse_sqr)\n",
    "print('*******************************************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Question 2:** Based on your results, what can you say about adding this term $age^2$ to your model?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Including categorical features\n",
    "It is well known that the position where a football player plays has an impact in his market value. Midfielders and stikers tend to be more expensive. *Your goal now is to include this information in the model.*  \n",
    "\n",
    "As seen from the description, the player position is encoded as a numeric variable (1, 2, 3, 4). However, they represent categories and not values on their own. Categorical variables are commonly encoded under a scheme denoted 1-of-K encoding. This allows to convert a variable representing K different categories into K different binary values. Example: \n",
    "\n",
    "| **attacker**   |     **midfielder** | **defender** | **goalkeeper**      |  \n",
    "|-------------|-------------|-------------|-------------|\n",
    "| 1   |  0 | 0 | 0 |\n",
    "| 0   |  1 | 0 | 0 |\n",
    "| 0   |  0 | 1 | 0 |\n",
    "| 0   |  0 | 0 | 1 |\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 3:** Implement 1-of-K encoding and complete the code below so that your model includes information about a player's position\n",
    "\\begin{equation}\n",
    " \\hat{y} = w_0 + w_1x_{age} + w_2x_{fplavalue} + w_3x_{bigclub} + w_4x_{pageviews} + w_5x_{age}^2 + w_6x_{attaker} + w_7x_{midfielder} + w_8x_{defender} +w_9x_{goalkeeper}\n",
    "\\end{equation}    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X_with_position(ds):\n",
    "    #Your code here\n",
    "    X_cols = ds[['age', 'fpl_value', 'big_club', 'position_cat']].copy()\n",
    "    X_cols['sqrt_page_views'] = np.sqrt( ds[['page_views']])\n",
    "   \n",
    "    #Your code here\n",
    "    \n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos = prepare_X_with_position(train)\n",
    "X_pos_test = prepare_X_with_position(test)\n",
    "\n",
    "W_pos = utils.fit_model(X_pos, y_train)\n",
    "mse_pos = run(W_pos,X_pos, y_train)\n",
    "\n",
    "print('***************************** Results with player\\'s position *******************************************')\n",
    "print('[W_0,W] : [', W_pos[0],',', W_pos[1:], ']' )\n",
    "print('MSE: ', mse_pos)\n",
    "print('*******************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('***************************** Summary: Training error *******************************************')\n",
    "print('MSE model 1: ', mse)\n",
    "print('MSE model 2: ', mse_sqr)\n",
    "print('MSE model 3: ', mse_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('***************************** Summary: Test error *******************************************')\n",
    "print('MSE model 1: ', run(W,X_test, y_test))\n",
    "print('MSE model 2: ', run(W_sqr,X_sqr_test, y_test))\n",
    "print('MSE model 3: ', run(W_pos,X_pos_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Question 3:** Based on your results, what can you say about adding the player's position to your model?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 4:** To deal with the apparent non-linear relationship between age and market value, \n",
    "<a href=\"https://www.kaggle.com/mauryashubham/linear-regression-to-predict-market-value/data\">Shubham Maurya</a> suggests to use categorical features for the age. Using your implementation of the 1-of-K encoding, include the age categorical features into the model. \n",
    "\n",
    "It is up to you to decide if you will keep or not currently used $x_{age}$ and $x_{age}^2$. Whichever your choice is, <u>justify clearly your answer</u>. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X_with_position_and_age(ds):\n",
    " \n",
    "    #Your code here\n",
    "    \n",
    "    return X\n",
    "\n",
    "#Your answer here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pa = prepare_X_with_position_and_age(train)\n",
    "X_pa_test = prepare_X_with_position_and_age(test)\n",
    "\n",
    "W_pa = utils.fit_model(X_pa, y_train)\n",
    "mse_pa = run(W_pa,X_pa, y_train)\n",
    "\n",
    "print('*************** Results with player\\'s position and age cat features***********************')\n",
    "print('[W_0,W] : [', W_pa[0],',', W_pa[1:], ']' )\n",
    "print('MSE: ', mse_pa)\n",
    "print('*******************************************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In summary:** Let's summarize all the results obtained so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('***************************** Summary: Training error *******************************************')\n",
    "print('MSE model 1: ', mse)\n",
    "print('MSE model 2: ', mse_sqr)\n",
    "print('MSE model 3: ', mse_pos)\n",
    "print('MSE model 4: ', mse_pa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Question 4:** Based on these results, which model would you choose to predict a player's market value? Justify your answer.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4 - Prediction:** Now, let use the models to predict the market value of the players in the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('***************************** Summary: Test error *******************************************')\n",
    "print('MSE model 1: ', run(W,X_test, y_test))\n",
    "print('MSE model 2: ', run(W_sqr,X_sqr_test, y_test))\n",
    "print('MSE model 3: ', run(W_pos,X_pos_test, y_test))\n",
    "print('MSE model 4: ', run(W_pa,X_pa_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Question 5:** How did your model do? Was it the best performing? Based on your intuition (as this topic has not been yet covered), try to explain the obtained performance (i.e. why some models do better than others)? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Linear Models for Classification\n",
    "\n",
    "\n",
    "In this part, we will be working with the <a href=\"https://archive.ics.uci.edu/ml/datasets/heart+Disease\">Heart Disease dataset</a>, from the <a href=\"https://archive.ics.uci.edu/ml/index.php\">UCI Machine Learning Repository</a>. \n",
    "\n",
    "This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database that we will use is the only one that has been used by ML researchers to this date. The \"diagnosis\" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4. Additionally, there is a condition field that labels subjects as healthy (H, which is equivalent to condition 0) or with a diagnosed disease (D, which gathers any subject with condition 1-4). \n",
    "\n",
    "Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).\n",
    "\n",
    "**The goal of this section is to build two classifiers: ona that can discriminate healthy from diseased subjects and a second one that can precisely identify the diagnosis of a subject.**\n",
    "\n",
    "The dataset contains the following information:\n",
    "\n",
    "| **Field**   |     **Description**      |  \n",
    "|-------------|-------------|\n",
    "| age         |  age in years |\n",
    "| sex         |  (1 = male; 0 = female) |\n",
    "|cp           |chest pain type |\n",
    "|trestbps     |resting blood pressure (in mm Hg on admission to the hospital)|\n",
    "|cholserum  |  cholestoral in mg/dl|\n",
    "|fbs        |(fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)|\n",
    "|restecg | resting electrocardiographic results|\n",
    "|thalach |maximum heart rate achieved|\n",
    "|exang | exercise induced angina (1 = yes; 0 = no)|\n",
    "|oldpeak | ST depression induced by exercise relative to rest |\n",
    "|slope |the slope of the peak exercise ST segment |\n",
    "|ca | number of major vessels (0-3) colored by flourosopy |\n",
    "|thal | 3 = normal; 6 = fixed defect; 7 = reversable defect|\n",
    "| diagnosis | 0= normal, 1,2,3,4 disease conditions|\n",
    "| condition | H=Healthy D=Diseased |\n",
    "\n",
    "**Step 1:** As usual, we start by inspecting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df_full = pd.read_csv(\"data/processed.cleveland.data\")\n",
    "\n",
    "#The dataset contains some missing values. We are filtering them out here\n",
    "heart_df = []\n",
    "heart_df = heart_df_full[~(heart_df_full == '?').any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 - Prepare the data:** First, we will split the data into a training and a testing dataset. For this lab, the data has already been split for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_heart.csv')\n",
    "test = pd.read_csv('data/test_heart.csv')\n",
    "\n",
    "x_train = train.drop(['condition','diagnosis'], axis=1)\n",
    "y_train = train['condition']\n",
    "\n",
    "x_test = test.drop(['condition','diagnosis'], axis=1)\n",
    "y_test = test['condition']\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use all the available features to train our two models. However, as it seems that there are some categorical features, there is need to do some data pre-processing.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 5:** Complete the function below which prepares the input data. You can re-use your code for the 1-to-K encoding.  \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(ds):\n",
    "    #Your code here\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "**Question 6:** Which features have you encoded? <u>justify your answer</u>. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf = prepare_data(x_train)\n",
    "X_clf_test = prepare_data(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary classification\n",
    "We will first use the input data to train a binary classifier using Logistic Regression. \n",
    "This time, we will use the algorithm as implemented by the library <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">scikit-learn.</a>\n",
    "\n",
    "The code has been included in the <code>utils.py</code> file.\n",
    "\n",
    "**Step 3 - Training** is just about calling the function in utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = utils.fit_logreg(X_clf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look at the estimated parameters ($\\hat{\\mathbf{W}}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*************** Estimated parameters: ***********************')\n",
    "print('[W_0,W] : [',logreg.intercept_,',', logreg.coef_, ']' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Question 7:** Based on these results, what can you say about the incidence of age in having a heart disease? Of Cholesterol? <u>justify your answer</u>. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4 - Predict:** Similarly as we did with the linear regression part, the function below collects the steps needed to predict the output of new data and to then assess the performance. To measure the performance of a classifier we will use accuracy. We define accuracy as:\n",
    "\n",
    "\\begin{equation}\n",
    "accuracy = \\dfrac{\\#correct}{\\#samples}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\#correct$ denotes the number of correctly classified samples and $\\#samples$ the total number of samples under consideration.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 6:** Complete the function by adding the necessary code to compute accuracy.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_test(model, X_test, y_test):\n",
    "    '''\n",
    "    Predicts using a model received as input and then evaluates the accuracy of the predicted data. \n",
    "    As inputs it receives the model, an input dataset X_test and the corresponding targets (ground thruth) y_test\n",
    "    It returs the classification accuracy.\n",
    "    '''\n",
    "    y_hat =model.predict(X_test)\n",
    "    \n",
    "    #Your code here\n",
    "\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = predict_and_test(logreg,X_clf, y_train)\n",
    "\n",
    "print('*******************  Training accuracy (identifying diseased condition) ***************************')\n",
    "print('ACC: ', acc)\n",
    "print('*******************************************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Question 8:** Is your model capable of differentiating healthy subjects from patients? <u>justify your answer</u>. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting feature of logistic regression is that it hands back *probabilities* of a given case being 1 or 0, rather than just 1s and 0s. That allows to do  set different cutoffs for what counts as a 1. Let us have a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_thresholds(model, X, y, thresh):\n",
    "    '''\n",
    "    Computes accuracies by varying the cut-off threshold given a model, the input data and a range of thresholds. A ground truth needs to be provided\n",
    "    to estimate the accuracy\n",
    "    Works specifically for the Cleveland dataset.\n",
    "    '''\n",
    "    y_bool = (y == 'H')\n",
    "    accs = [(np.sum(y_bool ==  ~(model.predict_proba(X)[:,0] >= t)) / len(y)) for t in thresh]\n",
    "    \n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a range of thresholds from 0 to 1.\n",
    "h=.02\n",
    "x_min=0.0\n",
    "x_max=1.0\n",
    "\n",
    "thresh=np.arange(x_min, x_max, h)\n",
    "accs = explore_thresholds(logreg, X_clf, y_train, thresh)\n",
    "plt.rcParams['figure.figsize'] = [9.5, 6]\n",
    "plt.scatter(thresh, accs)\n",
    "plt.xlabel('Cut-off threshold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training accuracy as a function of the cut-off threshold')\n",
    "plt.axvline(x=0.5,color='gray', linestyle='--') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dashed line denotes the threshold value used \"by default\". \n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Question 9:** Based on this results, would you rather use your \"personalized\" threshold to predict future samples? If yes, which value? <u>justify your answer</u>. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you chose a specific threshold value to use as cut-off replace 0.5 with your chosen value (or with any value)\n",
    "custom_t = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us use the model(s) to predict the unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('******************  Testing accuracy (identifying diseased condition) *********************')\n",
    "print('ACC: ', predict_and_test(logreg,X_clf_test, y_test))\n",
    "print('*******************************************************************************************')\n",
    "\n",
    "#If you chose a specific threshold value to use as cut-off this will be displayed\n",
    "if custom_t != 0.5:\n",
    "    print('*********  Testing accuracy with custom cut-off (identifying diseased condition)***********')\n",
    "    print('ACC: ',explore_thresholds(logreg, X_clf_test, y_test, [custom_t])[0])\n",
    "    print('*******************************************************************************************')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial classification\n",
    "Now, we want to know the precise diagnosis of a subject and not just to identify their overall condition (healthy or sick). For that purpose we will use a multinomial classifier. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 7:** Code all the necessary steps to train a multinomial logistic regression model and then predict the outputs of unseen data using it. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume there is a dummy model that outputs healthy (diagnosis=0) for every single input. The code below implements such a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_model(X):\n",
    "    '''\n",
    "    Returns a zero (no disease) no matter the input\n",
    "    '''\n",
    "    return np.zeros(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 8:** Compare the accuracy of your model and the dummy model on the testing data.\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_dummy = dummy_model(X_clf_test)\n",
    "\n",
    "#Your code here\n",
    "\n",
    "print('******************  Testing accuracy *********************')\n",
    "print('ACC multinomial: ', acc_test)\n",
    "print('ACC dummy: ', acc_dummy)\n",
    "print('**********************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Question 10:** Which one is better? What can you say about your model based on these results? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Comparing to a different family of methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last part of the lab, we are going to compare logistic regression to a different type of methods that we have not covered in the course and, more specifically, the k nearest neighbors algorithm (kNN).\n",
    "\n",
    "kNN is considered a non-parametric method given that it makes few assumptions about the form of the data distribution. This approach is *memory-based* as it requires no model to be fit. Nearest-neighbor methods use the observations from the training set closest in input space to $x$ to form $\\hat{y}$. It is based on the assumption that if a sample's features are similar to the ones of points of one particular class then it belongs to that class. These points are known as nearest neighbors.\n",
    "\n",
    "The specific case where $k=1$ is denoted the nearest neighbor algorithm. Here $\\hat{y}$ is assigned the value $y_{l}$ of the closest point $x_{l}$ to $x$ in the training data. This corresponds to a *Voronoi tessellation* of the training data. \n",
    "\n",
    "#### Algorithm\n",
    "Given a query point $\\mathbf{x}_0$ and a training set $T=(\\mathbf{x}_i, y_i)$, $i = 1,..., N$:<br>\n",
    "1- Compute the distance $d(\\mathbf{x}_0, \\mathbf{x}_i)$ between $\\mathbf{x}_0$ and all $\\mathbf{x}_i \\in T$.<br>\n",
    "2- Sort all $ \\mathbf{x}_i$ using $d(\\mathbf{x}_0, \\mathbf{x}_i)$ as sorting criterion.<br>\n",
    "3- Select the first $K$ points. This points are denoted the k-neighborhood of $\\mathbf{x}_0$, $N_k(\\mathbf{x}_0)$.<br>\n",
    "4- Assign $\\hat{y}(\\mathbf{x}_0$) based on majority voting:\n",
    "\\begin{equation}\n",
    "\\hat{y}(\\mathbf{x}_0) = \\arg\\max_{y} \\sum_{\\mathbf{x}_i \\in N_k} I(y = y_i)\n",
    "\\end{equation}\n",
    "\n",
    "An illustration of the algorithm is shown below:\n",
    "<center>\n",
    "<img src=\"data/knn.png\" width=\"200\" />\n",
    "\n",
    "The test sample (green dot) should be classified either to blue squares or to red triangles. If k = 3 (solid line circle) it is assigned to the red triangles because there are 2 triangles and only 1 square inside the inner circle. If k = 5 (dashed line circle) it is assigned to the blue squares (3 squares vs. 2 triangles inside the outer circle). Source: <a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\">Wikipedia</a>.    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 9:** Your first task is to implement the K nearest neighbor algorithm by completing the code below. Use the Euclidean distance to measure the distance between two points.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "class KNN:\n",
    "    def __init__(self, K):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.k = K\n",
    "        \n",
    "    def train(self,X,y): \n",
    "        #Your code here\n",
    "       \n",
    "    def predict(self,X_new):\n",
    "        #Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing your implementation\n",
    "To evaluate the algorithm we are going to use synthetic data coming from a Gaussian mixture model composed of 3 multivariate Gaussian distributions with different means and common covariance. Data is obtained by calling the function <code>gaussians()</code> from the <code>utils.py</code> file.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 10:** Complete the code below in order to build a model using your K-NN implementation and then predict for unseen data. The obtained results will be compared with those obtained using scikit-learn implementation. \n",
    "    \n",
    "Test for different values of K. Comment on the obtained results. You can add images to your notebook using ```<img src=\"path/to/image.png\" />```\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = utils.gaussians()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "\n",
    "h=.02\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "X_test = np.c_[xx.ravel(), yy.ravel()] #This is the testing data\n",
    "\n",
    "K=1\n",
    "knn = KNN(K)\n",
    "#----------------------------- Your code here -------------------------------------\n",
    "\n",
    "#here!\n",
    "\n",
    "#--------------------------- end of your code --------------------------------------\n",
    "\n",
    "# Put the result into a color plot\n",
    "y_test = y_test.reshape(xx.shape)\n",
    "\n",
    "#Scikit-learn implementation\n",
    "clf = neighbors.KNeighborsClassifier(K, algorithm='kd_tree') #, weights=weights)\n",
    "clf.fit(X, y)\n",
    "Z = clf.predict(X_test)\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)    \n",
    "\n",
    "\n",
    "#Compare results\n",
    "utils.comparing_plots(xx,yy, X, y, Z, y_test, \"Scikit learn\", \"Your implementation with K=\" + str(K))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing KNN and Logistic regression\n",
    "Finally, we will compare the behaviour of a linear model, such as logistic regression, with KNN. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 10:** Using code from Part 2, train a logistic regression model with the data from the iris dataset and then predict the unseen samples <code>X_test</code>. Store your results in a variable called <code>logistic_results</code>. This will be used to plot the regions defined by the decision functions of the logistic regressor.\n",
    "    \n",
    "Train your KNN classifier, with a K of your choice and then predict the unseen samples. Store the results in a variable called <code>knn_results</code>.\n",
    "   \n",
    "Have a look at the plots:\n",
    "\n",
    "    1) What can you say of the behaviour of the two models? \n",
    "    2) Play around with your K. What changes do you see? Which value of K would you recommend to get decision boundaries similar to those of logistic regression?\n",
    "    3) Based on your results, when would you recommend to use KNN? When a linear model?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Your logistic regression code here:\n",
    "\n",
    "# Put the result into a color plot\n",
    "logistic_results = logistic_results.reshape(xx.shape)  \n",
    "\n",
    "# 2) Your KNN code here\n",
    "\n",
    "# Put the result into a color plot\n",
    "knn_results = knn_results.reshape(xx.shape)\n",
    "\n",
    "\n",
    "#Compare results\n",
    "utils.comparing_plots(xx,yy, X, y, logistic_results, knn_results, \"Logistic regression\", \"Your KNN with K=\" + str(K))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
